{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d513603-fb9b-427e-8a03-c8ac217615ba",
   "metadata": {},
   "source": [
    "## Neural Network - Approche Deep **AVEC** Data AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec91915-5577-433b-9db3-f8b3a0a669da",
   "metadata": {},
   "source": [
    "### Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rural-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\adrien\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\adrien\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\adrien\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\adrien\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\adrien\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\adrien\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\adrien\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\adrien\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\adrien\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\adrien\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\adrien\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\adrien\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import itertools\n",
    "import fnmatch\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import math\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d876bd6b-b610-4fcd-b09a-3eefd1b58c9c",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "first-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recherche des fichiers de manière automatisé en fournissant le chemin\n",
    "from glob import glob\n",
    "imagePatches = glob('Wang/*.jpg', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "authorized-islam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wang\\\\0.jpg',\n",
       " 'Wang\\\\1.jpg',\n",
       " 'Wang\\\\10.jpg',\n",
       " 'Wang\\\\100.jpg',\n",
       " 'Wang\\\\101.jpg',\n",
       " 'Wang\\\\102.jpg',\n",
       " 'Wang\\\\103.jpg',\n",
       " 'Wang\\\\104.jpg',\n",
       " 'Wang\\\\105.jpg',\n",
       " 'Wang\\\\106.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagePatches[:10] #10 premières images récupérées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promotional-specialist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imagePatches) #on retrouve bien les 1000 images de notre base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "neither-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_path = 'Wang/145.jpg'\n",
    "filename = os.path.basename(your_path) #définition de la base du path de nos images\n",
    "filename = floor( int(filename.split('.')[0]) / 100 ) #récupération du numéro de notre image\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "developmental-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [] #nos images\n",
    "y = [] #nos labels\n",
    "#définition de la taille de nos images\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "#pourchaque image de notre chemin\n",
    "for img in imagePatches:\n",
    "    filename = os.path.basename(img)\n",
    "    label = floor( int(filename.split('.')[0]) / 100 ) #récupération du numéro de notre image\n",
    "    y.append(label)\n",
    "    \n",
    "    full_size_image = cv2.imread(img)\n",
    "    x.append(cv2.resize(full_size_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC)) \n",
    "    #redimensionnement de l'image en suivant une inter-polation cubique\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "saving-zealand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape #test taille de notre première image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5565e33e-f2fb-465d-9eca-0bb15cc7c767",
   "metadata": {},
   "source": [
    "### Learning Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "primary-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(x)\n",
    "#Normalisation de notre data set\n",
    "X=X/255.0\n",
    "\n",
    "### Découpage en apprentissage/test des données\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brief-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des labels des iumages  en  \"hot vectors\" \n",
    "#(ex : 5 -> [0,0,0,0,1,0,0,0,0,0])\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_trainHot = to_categorical(Y_train, num_classes = 10)\n",
    "y_testHot = to_categorical(Y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35aa89d-9b6b-4835-a759-4a0eca417892",
   "metadata": {},
   "source": [
    "### Définition des métriques et évaluations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "difficult-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCheckpoint(Callback):\n",
    "    \"\"\"Classe qui sauvegarde les metrics pour chaque epoch. Principe utilisé fréquemment dans \n",
    "    les réseaux de neurones pour visualiser l'évolution des étapes d'apprentissage\"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unavailable-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evolution du taux d'apprentisssage précision par epochs\n",
    "\n",
    "def plotKerasLearningCurve():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Fonction qui affiche les matrices de confusion\n",
    "    La normalisation peut être appliquée ou non\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97247aaa-e2f1-4070-a75e-9f7dccf6cf3a",
   "metadata": {},
   "source": [
    "### Paramétrage de notre CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "renewable-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "img_rows,img_cols=256,256\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "e = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86018e1-0fa6-44d0-a1b5-a4155fe9a6aa",
   "metadata": {},
   "source": [
    "### Définition de notre CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "vocal-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape,strides=e))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87109f96-2535-428f-ba0c-e69165a254a6",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pressing-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation du nombre d'images par la normalisation, la rotation, les décalages, \n",
    "#les retournements, le changement de luminosité etc ...\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  #fixe la moyenne d'entrée à 0 sur l'ensemble des données\n",
    "        rotation_range=20,  # random rotation des images allant de 0 à 180 degrés\n",
    "        height_shift_range=0.2,  #déplacement aléatoire des images verticalement (fraction de la longueur/hauteur totale)\n",
    "        width_shift_range=0.2,  # déplacement aléatoire des images horizontalement (fraction de la largeur totale)\n",
    "        horizontal_flip=True,  # retournement aléatoire des images à l'horizontal\n",
    "        vertical_flip=True)  # retournement aléatoire des images à la verticale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "surgical-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= X_train.astype(np.uint8)\n",
    "train_hot = y_trainHot\n",
    "test = X_test\n",
    "test_hot = y_testHot\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b8211-0675-4995-b258-dafc530d7e60",
   "metadata": {},
   "source": [
    "### Apprentissage et Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915abc9d-7491-4105-9716-bc1061ed6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(datagen.flow(train,train_hot, batch_size=5),\n",
    "                        steps_per_epoch=len(train) / 32, \n",
    "                              epochs=epochs,validation_data = [test, test_hot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c54c1-b0fa-4345-84e0-ecb35cb34d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotKerasLearningCurve()\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
